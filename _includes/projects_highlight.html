<div class="media">
  <a class="pull-left" href="assets/img/scdi_long.png">
    <img class="media-object" src="assets/img/scdi.png" width="96px" height="96px"/>
  </a>
  <div class="media-body">
    <p class="media-heading">
      <strong>Sparse Correlated Diffusion Imaging: A New Computational Diffusion MRI Modality for Prostate Cancer Detection</strong><br />
      <a href="#">J. Zhang, 
      <a href="https://sites.google.com/site/farzadkhalvati/">F. Khalvati</a>, 
      <a href="http://medical-imaging.utoronto.ca/node/348">M.A. Haider</a>, 
      <a href="http://www.eng.uwaterloo.ca/~a28wong/index.html">A. Wong</a>.  
      <!--<br />-->
      <a href="assets/pdf/JCVIS16_scdi.pdf">[PDF]</a>
      <a href="assets/img/scdi_presentation2.png">[Slide]</a>   
      <br />
      Research Themes: Computational diffusion MRI, Quantitative Imaging, Numeric Optimization
    </p>
    
    <p class="abstract-text">
    Computational diffusion MRI (CD-MRI) aims to leverage computational means to 
    generate imagery from diffusion signals which are easier to interpret by human 
    experts. We introduced a new CD-MRI modality called sparse correlated diffusion 
    imaging (sCDI), which can improve the separability of cancerous and healthy 
    tissue in prostate gland, thus the diagnostic accuracy of proaste cancer.
    <!--Computational diffusion MRI (CD-MRI) aims to leverage computational means to 
    generate imagery from diffusion signals which are easier to interpret by human 
    experts. In this research We introduced a new CD-MRI modality called sparse 
    correlated diffusion imaging (sCDI), which improves the separability of cancerous 
    and healthy tissue in prostate gland by selecting an optimally sparse subset of 
    diffusion signals and mixing them together. The improved ability to separate 
    cancerous and healthy regions in prostate using sCDI can improve diagnostic 
    accuracy of proaste cancer and reduce the need for invasive methods such as biopsy.,-->
    </p> 
  </div>
</div>

<div class="media">
  <a class="pull-left" href="assets/img/procanvas_big.png">
    <img class="media-object" src="assets/img/pro.png" width="96px" height="96px"/>
  </a>
  <div class="media-body">
    <p class="media-heading">
      <strong>ProCanVAS: A Comprehensive Platform for Prostate Cancer Visualization and Analysis</strong><br />
      J. Zhang, F. Khalvati, M.A. Haider. 
      <a href="assets/img/procanvas_big.png">[Resources coming soon]</a>
      <br/>
      Research Themes: Computer-Aided Diagnosis (CAD), Machine Learning, Computer Vision, Radiomics 
      
    </p>
    <p class="abstract-text">
    I led the developement of ProCanVAS at Sunnybrook Research Institute, Toronto, ON, 
    Canada. The platform is a complete clinical decision support system. It integrates
    a range of imaging processing, computer vision and machine learning algorithms and
    provides modules for computational diffusional MRI, image contouring, radiomics 
    feature extraction, and prostate cancer detection.
    </p> 
  </div>
</div>

<div class="media">
  <a class="pull-left" href="assets/img/radiomics.jpg">
    <img class="media-object" src="assets/img/workflow.jpg" width="96px" height="96px"/>
  </a>
  <div class="media-body">
    <p class="media-heading">
      <strong>Predictive/Prognosis models based on Quantitative Radiomics and Clinic Data for Lung and Prostate Cancer</strong><br />
      J. Zhang, Y. Zhang, F. Khalvati, M.A. Haider. 
      <a href="assets/img/prostate_radiomics.png">[Resources coming soon]</a>
      <br/>
      Research Themes: Radiomics, Predictive Model, Feature Selection, Classification,
      data analysis      
    </p>
    <p class="abstract-text">
    <!--Radiomics characterizes tumour phenotypes by extracting a large number of quantitative features from regions of interest on radiological images. -->
    Radiomic features have been shown to provide prognostic value in predicting clinical outcomes in several studies. However, feature redundancy, unbalanced outcomes, and small sample sizes have led to relatively low predictive accuracy. The goal of the study is to explore different strategies for overcoming these challenges and improving the predictive performance of radiomics-based prognosis analysis for non-small cell lung cancer (NSCLC) and prostate cancer.
    </p> 
  </div>
</div>

<div class="media">
  <a class="pull-left" href="assets/img/tree.png">
    <img class="media-object" src="assets/img/als.png" width="96px" height="96px"/>
  </a>
  <div class="media-body">
    <p class="media-heading">
      <strong>Stochastc Models for Object Detection from Remote Sensed Data</strong><br />
      J. Zhang, G. Sohn. 
      <a href="#">[Slide]</a>
      <a href="http://jmlr.org/proceedings/papers/v28/jia13.pdf">[PDF]</a>
      <a href="https://youtu.be/La9uhfBNMEg">[Demo]</a>
      <br />
      Research theme: Stochastic processes, Probabilistic Model, Markov Chain Monte Carlo (MCMC), Parameter Estimation, Model Optimization
    </p>
    <p class="abstract-text">
    It is marvelous that human can detect objects of variations with ease in complex 
    scene, a challenge many existing machine vision systems fail to do.
    In the demo, we presented a stochastic model to detect single trees in forests
    from airborne laser scanning (ALS) data. The model integrates low-level image
    processing techniques into a high-level probabilistic framework. The configuration 
    containing the best possible set of trees is estimated by a Markov Chain 
    Monte Carlo (MCMC) dynamics coupled with a simulated annealing.
    <!-- It is marvelous that human can learn concept from a small number of examples, a challenge many existing machine vision systems fail to do. We present a system combining computer vision and cogscience to model such human behavior, as well as a new dataset for future experientation on human concept learning. -->
    </p> 
  </div>
</div>

<div class="media">
  <a class="pull-left" href="assets/img/icesat.png">
    <img class="media-object" src="assets/img/icesat_white.jpg" width="96px" height="96px"/>
  </a>
  <div class="media-body">
    <p class="media-heading">
      <strong>Derivation of forest vertical and horizontal information from large-footprint spaceborne LiDAR waveforms</strong><br />
      J. Zhang, Y. Xing, A. de Gier. 
      <a href="http://jmlr.org/proceedings/papers/v28/jia13.pdf">[PDF]</a>
      <a href="assets/img/fullwaveform.png">[Slide]</a>
      <a href="assets/img/regression.png">[Demo1]</a>
      <a href="assets/img/fullwaveform_feature.png">[Demo2]</a>
      <br />
      Research theme: Full-waveform analysis, Feature Engineering, Regression Models, Support Vector Machine (SVM), ICESat, Spaceborne LiDAR, Forest
    </p>
    <p class="abstract-text">
    ICESat/GLAS is the first laser-ranging (lidar) instrument for continuous global observations of Earth put in space. We further explored its ability in deriving forest vertical and horizontal information in cool temperate forests. In this research, we first conceptualized a method to derive forest type information from large-footprint lidar waveform data.
    </p> 
  </div>
</div>




<!--

<div class="media">
  <a class="pull-left" href="#">
    <img class="media-object" src="assets/img/papers/iccv13_sa.png" width="96px" height="96px"/>
  </a>
  <div class="media-body">
    <p class="media-heading">
      <strong>Category Independent Object-level Saliency Detection</strong><br />
      Y Jia, M Han. ICCV 2013.
      <a href="#">[PDF coming soon]</a>
    </p>
    <p class="abstract-text">
    We proposed a simple yet efficient approach to combine high-level object models and low-level appearance information to perform saliency detection that identifies foreground objects.
    </p> 
  </div>
</div>

<div class="media">
  <a class="pull-left" href="#">
    <img class="media-object" src="assets/img/papers/icml13.png" width="96px" height="96px"/>
  </a>
  <div class="media-body">
    <p class="media-heading">
      <strong>On Compact Codes for Spatially Pooled Features</strong><br />
      Y Jia, O Vinyals, T Darrell. ICML 2013.
      <a href="http://jmlr.org/proceedings/papers/v28/jia13.pdf">[PDF]</a>
      <a href="assets/pdf/icml13_poster.pdf">[poster]</a>
      <a href=http://arxiv.org/abs/1301.5348>[ICLR workshop version]</a>
    </p>
    <p class="abstract-text">
      We analyzed the connection between codebook size and accuracy with the Nystrom sampling theory, and showed how this leads to better pooling-aware codebook learning methods.
    </p> 
  </div>
</div>

<div class="media">
  <a class="pull-left" href="#">
    <img class="media-object" src="assets/img/papers/nips12.png" width="96px" height="96px"/>
  </a>
  <div class="media-body">
    <p class="media-heading">
      <strong>Learning with Recursive Perceptual Representations</strong><br />
      O Vinyals, Y Jia, L Deng, T Darrell. NIPS 2012.
      <a href="assets/pdf/nips12_rsvm.pdf">[PDF]</a>
      <a href="assets/pdf/nips12_rsvm_poster.pdf">[Poster]</a>
    </p>
    <p class="abstract-text">
      We proposed R2SVM, an efficient algorithm to recursively learn deep nonlinear models by stacking linear SVMs with random projections.
    </p> 
  </div>
</div>

<div class="media">
  <a class="pull-left" href="#">
    <img class="media-object" src="assets/img/papers/cvpr12.png" width="96px" height="96px"/>
  </a>
  <div class="media-body">
    <p class="media-heading">
      <strong>Beyond Spatial Pyramids: Receptive Field Learning for Pooled Image Features</strong><br />
      Y Jia, C Huang, T Darrell. CVPR 2012.
      <a href="assets/pdf/cvpr12_pooling.pdf">[PDF]</a>
      <a href="assets/pdf/cvpr12_pooling_slides.pdf">[Slides]</a>
      <a href="assets/pdf/cvpr12_pooling_poster.pdf">[Poster]</a>
    </p>
    <p class="abstract-text">
      We showed the suboptimality of spatial pyramids in feature pooling, and proposed an efficient way to learn task-dependent receptive fields for better pooled features.
    </p>
  </div>
</div>

<div class="media">
  <a class="pull-left" href="#">
    <img class="media-object" src="assets/img/papers/uai12.png" width="96px" height="96px"/>
  </a>
  <div class="media-body">
    <p class="media-heading">
      <strong>Factorized Multi-modal Topic Model</strong><br />
      S Virtanen, Y Jia, A Klami, T Darrell. UAI 2012.
      <a href="assets/pdf/uai12_factorize.pdf">[PDF]</a>
    </p>
    <p class="abstract-text">
      We factorized the information contained in corresponding image and text with a novel HDP-based topic model that automatically learns both shared and private topics.
    </p>
  </div>
</div>

<div class="media">
  <a class="pull-left" href="#">
    <img class="media-object" src="assets/img/papers/nips11.png" width="96px" height="96px"/>
  </a>
  <div class="media-body">
    <p class="media-heading">
      <strong>Heavy-tailed Distances for Gradient Based Image Descriptors</strong><br />
      Y Jia, T Darrell. NIPS 2011.
      <a href="assets/pdf/nips11_gcl.pdf">[PDF]</a>
      <a href="assets/pdf/nips11_gcl_supp.pdf">[Supplementary Material]</a>
      <a href="assets/pdf/nips11_gcl_poster.pdf">[Poster]</a>
    </p>
    <p class="abstract-text">
      We examined the heavy-tailed noise distribution of gradient-based image descriptors, and proposed a new distance metric that yields higher feature matching performances.
    </p>
  </div>
</div>

<div class="media">
  <a class="pull-left" href="#">
    <img class="media-object" src="assets/img/papers/iccv11.png" width="96px" height="96px"/>
  </a>
  <div class="media-body">
    <p class="media-heading">
      <strong>Learning Cross-modality Similarity for Multinomial Data</strong><br />
      Y Jia, M Salzmann, T Darrell. ICCV 2011
      <a href="assets/pdf/iccv11_mm.pdf">[PDF]</a>
      <a href="assets/pdf/iccv11_mm_poster.pdf">[Poster]</a>
    </p>
    <p class="abstract-text">
      We propose a novel approach based on topic models and the Markov random field to capture the semantic relationships between documents from multiple modalities. 
    </p>
  </div>
</div>

<div class="media">
  <a class="pull-left" href="#">
    <img class="media-object" src="assets/img/papers/iccv11-b3do.png" width="96px" height="96px"/>
  </a>
  <div class="media-body">
    <p class="media-heading">
      <strong>A Category-level 3-D Database: Putting the Kinect to Work</strong><br />
      A Janoch, S Karayev, Y Jia, J Barron, M Fritz, K Saenko, T Darrell. ICCV-CDC4CV workshop 2011
      <a href="assets/pdf/iccv11_kinect.pdf">[PDF]</a>
      <a href="http://kinectdata.com/">[Dataset]</a>
    </p>
    <p class="abstract-text">
      We presented a dataset of color and depth image pairs collected from the Kinect sensor, gathered in real domestic and ofﬁce environments, for research on object-level recognition with multimodal sensor input.
    </p>
  </div>
</div>

-->
